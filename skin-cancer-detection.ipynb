{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9443631,"sourceType":"datasetVersion","datasetId":5739163}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Initialization","metadata":{}},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom tqdm.auto import tqdm\n\nimport ssl # Quickfix to torchaudio ssl error\nssl._create_default_https_context = ssl._create_unverified_context\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:32.170011Z","iopub.execute_input":"2024-12-13T01:54:32.170251Z","iopub.status.idle":"2024-12-13T01:54:37.806157Z","shell.execute_reply.started":"2024-12-13T01:54:32.170224Z","shell.execute_reply":"2024-12-13T01:54:37.805171Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Helper Function","metadata":{}},{"cell_type":"code","source":"def preprocessing(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n    image = cv2.resize(image, (224, 224))  # Resize to 224x224\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.transpose(image, (2, 0, 1))  # Convert to (C, H, W)\n    image = torch.tensor(image, dtype=torch.float32)\n    return image\n\ndef show_image(dataloader, index):\n    # Get a batch of data\n    data_iter = iter(dataloader)\n    images, labels = next(data_iter)\n\n    # Ensure the index is within the batch size\n    batch_size = images.size(0)\n    if index >= batch_size:\n        raise IndexError(f\"Index {index} is out of bounds for batch size {batch_size}\")\n\n    # Get the image and label at the specified index within the batch\n    image = images[index]\n    label = labels[index]\n\n    # If images were normalized, we might need to denormalize them\n    # For example, if we used transforms.Normalize(mean, std), we need to unnormalize\n    # Replace these mean and std values with those used in your transforms\n    mean = torch.tensor([0.485, 0.456, 0.406])\n    std = torch.tensor([0.229, 0.224, 0.225])\n    image = image * std[:, None, None] + mean[:, None, None]\n\n    # Convert tensor to numpy array\n    image_np = image.numpy().transpose((1, 2, 0))\n\n    # Clip values to [0,1] if necessary\n    image_np = np.clip(image_np, 0, 1)\n\n    plt.figure(figsize=(6, 6))\n    plt.title(f\"Label: {label.item()}\")  # Use label name if available\n    plt.imshow(image_np)\n    plt.axis('off')  # Hide axis ticks\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:37.807940Z","iopub.execute_input":"2024-12-13T01:54:37.808644Z","iopub.status.idle":"2024-12-13T01:54:37.817046Z","shell.execute_reply.started":"2024-12-13T01:54:37.808593Z","shell.execute_reply":"2024-12-13T01:54:37.816162Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Custom Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nfrom torch.utils.data import Dataset\nimport torch.nn.functional as F\nfrom torchvision import transforms\n\nclass Resize:\n    def __init__(self, size):\n        self.size = size  # (h, w)\n\n    def __call__(self, image):\n        image = F.interpolate(image.unsqueeze(0), size=self.size, mode='bilinear', align_corners=False)\n        return image.squeeze(0)\n\nclass SkinDataset(Dataset):\n    def __init__(self, root_dir, transform=None,group_mapping=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.label_to_index = {}\n        self.group_mapping = group_mapping if group_mapping else {}\n        \n        self._build_label_index()\n\n    def _build_label_index(self):\n        # List all folder names in the root directory\n        label_names = sorted([\n            d for d in os.listdir(self.root_dir)\n            if os.path.isdir(os.path.join(self.root_dir, d))\n        ])\n    \n        # Map original labels to groups (if specified)\n        # Fallback to original label if not in group_mapping\n        mapped_labels = [self.group_mapping.get(label, label) for label in label_names]\n    \n        # Create label-to-index mapping\n        unique_labels = sorted(set(mapped_labels))\n        self.label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n    \n        # Populate image paths and labels\n        for label_name in label_names:\n            label_dir = os.path.join(self.root_dir, label_name)\n            # Map to new group label (or fallback to original)\n            mapped_label = self.group_mapping.get(label_name, label_name)\n            label_index = self.label_to_index[mapped_label]\n    \n            for img_name in os.listdir(label_dir):\n                img_path = os.path.join(label_dir, img_name)\n                if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n                    self.image_paths.append(img_path)\n                    self.labels.append(label_index)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n\n        image = cv2.imread(img_path)\n        if image is None:\n            raise ValueError(f\"Failed to load image at path: {img_path}\")\n\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0  # Shape: (C, H, W)\n\n        if self.transform:\n            image = self.transform(image)\n        else:\n            image = F.interpolate(image.unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False).squeeze(0)\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:37.818441Z","iopub.execute_input":"2024-12-13T01:54:37.818940Z","iopub.status.idle":"2024-12-13T01:54:37.834192Z","shell.execute_reply.started":"2024-12-13T01:54:37.818903Z","shell.execute_reply":"2024-12-13T01:54:37.833469Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from torchvision import transforms\n\ngroup_mappings = {\n    \"Chickenpox\": \"non-cancer\",\n    \"Cowpox\": \"non-cancer\",\n    \"HFMD\": \"non-cancer\",\n    \"Healthy\": \"non-cancer\",\n    \"Measles\": \"non-cancer\",\n    \"Monkeypox\": \"non-cancer\",\n    # Add more mappings here if needed\n}\n\ndata_transforms = transforms.Compose([\n    Resize((224, 224)),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\ntrain_dataset = SkinDataset(root_dir='/kaggle/input/lesion-image/dataset/Train', transform=data_transforms,group_mapping=group_mappings)\ntest_dataset = SkinDataset(root_dir='/kaggle/input/lesion-image/dataset/Test', transform=data_transforms,group_mapping=group_mappings)\nvalid_dataset = SkinDataset(root_dir='/kaggle/input/lesion-image/dataset/Valid', transform=data_transforms,group_mapping=group_mappings)\n\nprint(train_dataset.label_to_index)\n\nfrom torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:37.835634Z","iopub.execute_input":"2024-12-13T01:54:37.835869Z","iopub.status.idle":"2024-12-13T01:54:39.125530Z","shell.execute_reply.started":"2024-12-13T01:54:37.835846Z","shell.execute_reply":"2024-12-13T01:54:39.124667Z"},"trusted":true},"outputs":[{"name":"stdout","text":"{'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'non-cancer': 5, 'nv': 6, 'vasc': 7}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"## Model construction","metadata":{}},{"cell_type":"code","source":"class MobileNetV3Model(nn.Module):\n    def __init__(self, num_classes, extractor_trainable: bool = True):\n        super(MobileNetV3Model, self).__init__()\n        mobilenet = models.mobilenet_v3_large(pretrained=True)\n        \n        self.feature_extractor = mobilenet.features\n        \n        for param in self.feature_extractor.parameters():\n            param.requires_grad = extractor_trainable\n        \n        self.out_features = mobilenet.classifier[0].in_features\n\n        self.classifier = nn.Sequential(\n            nn.Linear(self.out_features, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.feature_extractor(x)\n        \n        x = F.adaptive_avg_pool2d(x, 1).reshape(x.size(0), -1)\n        \n        x = self.classifier(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:39.126521Z","iopub.execute_input":"2024-12-13T01:54:39.126779Z","iopub.status.idle":"2024-12-13T01:54:39.132590Z","shell.execute_reply.started":"2024-12-13T01:54:39.126754Z","shell.execute_reply":"2024-12-13T01:54:39.131814Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class ResNetModel(nn.Module):\n    def __init__(self, num_classes, extractor_trainable=True):\n        super(ResNetModel, self).__init__()\n        resnet = models.resnet34(pretrained=True)\n        \n        if not extractor_trainable:\n            for param in resnet.parameters():\n                param.requires_grad = False\n        \n        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n        num_features = resnet.fc.in_features\n        self.fc = nn.Linear(num_features, num_classes)\n\n    def forward(self, x):\n        x = self.feature_extractor(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:39.133679Z","iopub.execute_input":"2024-12-13T01:54:39.133912Z","iopub.status.idle":"2024-12-13T01:54:39.148562Z","shell.execute_reply.started":"2024-12-13T01:54:39.133889Z","shell.execute_reply":"2024-12-13T01:54:39.147681Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import timm\nimport torch.nn as nn\n\nclass EfficientNetModel(nn.Module):\n    def __init__(self, num_classes, model_name=\"efficientnet_b2\", extractor_trainable=True):\n        super(EfficientNetModel, self).__init__()\n        # Load EfficientNet using timm\n        self.model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n        \n        if not extractor_trainable:\n            for param in self.model.parameters():\n                param.requires_grad = False\n            \n            # Ensure classifier remains trainable\n            for param in self.model.get_classifier().parameters():\n                param.requires_grad = True\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T01:54:39.149823Z","iopub.execute_input":"2024-12-13T01:54:39.150061Z","iopub.status.idle":"2024-12-13T01:54:40.561424Z","shell.execute_reply.started":"2024-12-13T01:54:39.150038Z","shell.execute_reply":"2024-12-13T01:54:40.560523Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Training and Validation Loop","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\nfrom sklearn.metrics import confusion_matrix, fbeta_score\n\ndef training_loop(model, epochs, optimizer, loss_fn, data_loader, val_loader, device, fold=0):\n    epoch_losses = []\n    best_val_accuracy = 0\n    best_model_weights = None\n\n    for epoch in range(epochs):\n        loop = tqdm(data_loader, total=len(data_loader), leave=False)\n        model.train()\n        mean_loss = 0\n\n        for _, (X, y) in enumerate(loop):\n            optimizer.zero_grad()\n\n            X, y = X.to(device), y.to(device)\n\n            pred = model(X)\n            loss = loss_fn(pred, y)\n            mean_loss += loss.item()\n\n            loss.backward()\n            optimizer.step()\n\n            loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n            loop.set_postfix(loss=loss.item())\n\n        mean_loss /= len(data_loader)\n        epoch_losses.append(mean_loss)\n\n        # Perform validation and track the best accuracy\n        _, val_accuracy, _, _ = validation_loop(model, loss_fn, val_loader, device)\n        print(f\"Epoch [{epoch+1}/{epochs}] completed. Avg loss: {mean_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n\n        # Save the model weights if validation accuracy improves\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            best_model_weights = model.state_dict()  # Save current model weights\n\n    # Restore the best weights at the end of training\n    if best_model_weights is not None:\n        model.load_state_dict(best_model_weights)\n        print(f\"Restored model weights from epoch with best validation accuracy: {best_val_accuracy:.2f}%\")\n\n    print(f\"Training fold {fold+1} completed.\")\n\n    return epoch_losses, best_val_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:40.562551Z","iopub.execute_input":"2024-12-13T01:54:40.562897Z","iopub.status.idle":"2024-12-13T01:54:40.571020Z","shell.execute_reply.started":"2024-12-13T01:54:40.562853Z","shell.execute_reply":"2024-12-13T01:54:40.570093Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:40.571998Z","iopub.execute_input":"2024-12-13T01:54:40.572243Z","iopub.status.idle":"2024-12-13T01:54:40.587284Z","shell.execute_reply.started":"2024-12-13T01:54:40.572220Z","shell.execute_reply":"2024-12-13T01:54:40.586506Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def validation_loop(model, loss_fn, data_loader, device):\n    model.eval()\n    size = len(data_loader.dataset)\n    num_batches = len(data_loader)\n    test_loss, correct = 0.0, 0\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for X, y in data_loader:\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass\n            outputs = model(X)\n\n            # Calculate loss\n            loss = loss_fn(outputs, y)\n            test_loss += loss.item()\n\n            # Get predicted classes\n            _, pred_labels = torch.max(outputs, 1)\n\n            # Calculate number of correct predictions\n            correct += (pred_labels == y).sum().item()\n\n            # Store predictions and true labels for metrics\n            all_preds.extend(pred_labels.cpu().numpy())\n            all_labels.extend(y.cpu().numpy())\n\n    # Average loss and accuracy\n    test_loss /= num_batches\n    accuracy = (correct / size) * 100\n\n    print(f\"Validation Error:\\n Accuracy: {accuracy:.2f}%, Avg loss: {test_loss:.4f}\\n\")\n\n    # Calculate confusion matrix\n    conf_matrix = confusion_matrix(all_labels, all_preds)\n\n    # Calculate F-beta score with beta=2\n    fbeta = fbeta_score(all_labels, all_preds, beta=2, average='weighted')\n\n    print(f\"F-beta Score (beta=2): {fbeta:.4f}\\n\")\n\n    return conf_matrix, accuracy, (all_labels, all_preds), fbeta","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:40.590329Z","iopub.execute_input":"2024-12-13T01:54:40.591280Z","iopub.status.idle":"2024-12-13T01:54:40.599233Z","shell.execute_reply.started":"2024-12-13T01:54:40.591244Z","shell.execute_reply":"2024-12-13T01:54:40.598473Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Model training","metadata":{}},{"cell_type":"code","source":"from torch import optim","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:40.600289Z","iopub.execute_input":"2024-12-13T01:54:40.600622Z","iopub.status.idle":"2024-12-13T01:54:40.613252Z","shell.execute_reply.started":"2024-12-13T01:54:40.600584Z","shell.execute_reply":"2024-12-13T01:54:40.612655Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def calculate_class_weights(dataset):\n    \"\"\"\n    Calculate class weights based on the frequency of each class in the dataset.\n    \n    Args:\n        dataset: A PyTorch dataset (e.g., DiabeticDataset).\n        \n    Returns:\n        class_weights: A tensor of class weights to be used in the loss function.\n    \"\"\"\n    # Get the labels from the dataset\n    labels = [label for _, label in dataset]\n\n    # Count the frequency of each class\n    class_counts = np.bincount(labels)\n    \n    # Calculate weights as the inverse of the frequency of each class\n    class_weights = 1.0 / class_counts\n    \n    # Normalize the weights to ensure stability\n    class_weights = class_weights / class_weights.sum()\n\n    # Convert the weights to a PyTorch tensor\n    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n    \n    return class_weights\n\n# Usage:\n# Calculate class weights based on the training dataset\nclass_weights = calculate_class_weights(train_dataset)\n\n# Move the class weights to the appropriate device\nclass_weights = class_weights.to(device)\n\n# Define the loss function with class weights\ncriterion = nn.CrossEntropyLoss(weight=class_weights)","metadata":{"execution":{"iopub.status.busy":"2024-12-13T01:54:40.614134Z","iopub.execute_input":"2024-12-13T01:54:40.614361Z","iopub.status.idle":"2024-12-13T01:56:22.713177Z","shell.execute_reply.started":"2024-12-13T01:54:40.614338Z","shell.execute_reply":"2024-12-13T01:56:22.712415Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = EfficientNetModel(8).to(device)\n\n# criterion = nn.CrossEntropyLoss()  # For multi-class classification\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Number of epochs\nnum_epochs = 20\n\n# Train the model\n'''\ntrain_losses = training_loop(\n    model=model, \n    epochs=num_epochs, \n    optimizer=optimizer, \n    loss_fn=criterion, \n    data_loader=train_loader, \n    device=device\n)\n'''\ntrain_losses, best_val_accuracy = training_loop(\n    model=model,\n    epochs=num_epochs,\n    optimizer=optimizer,\n    loss_fn=criterion,\n    data_loader=train_loader, # Match this name to your training DataLoader\n    val_loader=valid_loader,\n    device=device\n)\n\n# After training, validate the model\nconf_matrix, val_accuracy, (all_labels, all_preds), fbeta = validation_loop(\n    model, criterion, valid_loader, device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T01:56:22.714273Z","iopub.execute_input":"2024-12-13T01:56:22.714634Z","iopub.status.idle":"2024-12-13T02:34:33.462032Z","shell.execute_reply.started":"2024-12-13T01:56:22.714588Z","shell.execute_reply":"2024-12-13T02:34:33.461012Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/36.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b880fe11befa4675b7d00803ab95a972"}},"metadata":{}},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 67.31%, Avg loss: 0.8417\n\nF-beta Score (beta=2): 0.6794\n\nEpoch [1/20] completed. Avg loss: 1.6589, Val Accuracy: 67.31%\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 74.28%, Avg loss: 0.9055\n\nF-beta Score (beta=2): 0.7477\n\nEpoch [2/20] completed. Avg loss: 0.9193, Val Accuracy: 74.28%\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 71.32%, Avg loss: 0.8290\n\nF-beta Score (beta=2): 0.7230\n\nEpoch [3/20] completed. Avg loss: 0.7341, Val Accuracy: 71.32%\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 76.63%, Avg loss: 0.7244\n\nF-beta Score (beta=2): 0.7702\n\nEpoch [4/20] completed. Avg loss: 0.5853, Val Accuracy: 76.63%\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 82.65%, Avg loss: 0.7629\n\nF-beta Score (beta=2): 0.8228\n\nEpoch [5/20] completed. Avg loss: 0.4956, Val Accuracy: 82.65%\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 78.73%, Avg loss: 0.8124\n\nF-beta Score (beta=2): 0.7914\n\nEpoch [6/20] completed. Avg loss: 0.4060, Val Accuracy: 78.73%\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 80.12%, Avg loss: 0.9315\n\nF-beta Score (beta=2): 0.8000\n\nEpoch [7/20] completed. Avg loss: 0.3911, Val Accuracy: 80.12%\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 68.79%, Avg loss: 0.9741\n\nF-beta Score (beta=2): 0.6926\n\nEpoch [8/20] completed. Avg loss: 0.4126, Val Accuracy: 68.79%\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 75.59%, Avg loss: 0.9868\n\nF-beta Score (beta=2): 0.7532\n\nEpoch [9/20] completed. Avg loss: 0.3896, Val Accuracy: 75.59%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 76.55%, Avg loss: 0.9125\n\nF-beta Score (beta=2): 0.7691\n\nEpoch [10/20] completed. Avg loss: 0.3258, Val Accuracy: 76.55%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 79.69%, Avg loss: 0.9552\n\nF-beta Score (beta=2): 0.7974\n\nEpoch [11/20] completed. Avg loss: 0.3264, Val Accuracy: 79.69%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 83.17%, Avg loss: 1.0030\n\nF-beta Score (beta=2): 0.8249\n\nEpoch [12/20] completed. Avg loss: 0.3777, Val Accuracy: 83.17%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 82.91%, Avg loss: 0.9730\n\nF-beta Score (beta=2): 0.8273\n\nEpoch [13/20] completed. Avg loss: 0.2362, Val Accuracy: 82.91%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 82.65%, Avg loss: 1.3258\n\nF-beta Score (beta=2): 0.8238\n\nEpoch [14/20] completed. Avg loss: 0.2055, Val Accuracy: 82.65%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 81.43%, Avg loss: 1.0084\n\nF-beta Score (beta=2): 0.8143\n\nEpoch [15/20] completed. Avg loss: 0.1479, Val Accuracy: 81.43%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 72.97%, Avg loss: 1.1536\n\nF-beta Score (beta=2): 0.7338\n\nEpoch [16/20] completed. Avg loss: 0.3065, Val Accuracy: 72.97%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 79.77%, Avg loss: 1.0817\n\nF-beta Score (beta=2): 0.7964\n\nEpoch [17/20] completed. Avg loss: 0.4142, Val Accuracy: 79.77%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 81.34%, Avg loss: 0.9149\n\nF-beta Score (beta=2): 0.8131\n\nEpoch [18/20] completed. Avg loss: 0.1865, Val Accuracy: 81.34%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 81.78%, Avg loss: 1.1535\n\nF-beta Score (beta=2): 0.8166\n\nEpoch [19/20] completed. Avg loss: 0.1519, Val Accuracy: 81.78%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Validation Error:\n Accuracy: 83.09%, Avg loss: 1.3611\n\nF-beta Score (beta=2): 0.8275\n\nEpoch [20/20] completed. Avg loss: 0.1412, Val Accuracy: 83.09%\nRestored model weights from epoch with best validation accuracy: 83.17%\nTraining fold 1 completed.\nValidation Error:\n Accuracy: 83.09%, Avg loss: 1.4744\n\nF-beta Score (beta=2): 0.8275\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T02:34:33.463177Z","iopub.execute_input":"2024-12-13T02:34:33.463509Z","iopub.status.idle":"2024-12-13T02:34:33.468692Z","shell.execute_reply.started":"2024-12-13T02:34:33.463481Z","shell.execute_reply":"2024-12-13T02:34:33.467833Z"}},"outputs":[{"name":"stdout","text":"[[ 20   1   6   0   5   0   1   0]\n [  1  45   1   0   0   0   7   0]\n [  4   3  82   1  11   0   9   0]\n [  2   0   3   3   1   0   4   0]\n [  3   3  21   0  44   0  52   1]\n [  0   0   0   0   0 143   1   0]\n [  2   1  18   3  28   0 602   1]\n [  0   0   0   0   0   0   0  14]]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ntarget_names = ['akiec','bcc','bkl','df','mel','non-cancer','nv','vasc']\nreport = classification_report(all_labels, all_preds,target_names=target_names)\nprint(\"\\nClassification Report:\\n\", report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T02:34:33.469930Z","iopub.execute_input":"2024-12-13T02:34:33.470724Z","iopub.status.idle":"2024-12-13T02:34:33.489177Z","shell.execute_reply.started":"2024-12-13T02:34:33.470689Z","shell.execute_reply":"2024-12-13T02:34:33.488343Z"}},"outputs":[{"name":"stdout","text":"\nClassification Report:\n               precision    recall  f1-score   support\n\n       akiec       0.62      0.61      0.62        33\n         bcc       0.85      0.83      0.84        54\n         bkl       0.63      0.75      0.68       110\n          df       0.43      0.23      0.30        13\n         mel       0.49      0.35      0.41       124\n  non-cancer       1.00      0.99      1.00       144\n          nv       0.89      0.92      0.90       655\n        vasc       0.88      1.00      0.93        14\n\n    accuracy                           0.83      1147\n   macro avg       0.72      0.71      0.71      1147\nweighted avg       0.82      0.83      0.82      1147\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nprint(\"Accuracy:\", accuracy_score(all_labels, all_preds))\nprint(\"Precision:\", precision_score(all_labels, all_preds, average='weighted'))  # Use 'weighted' for multiclass\nprint(\"Recall:\", recall_score(all_labels, all_preds, average='weighted'))        # Use 'weighted' for multiclass\nprint(\"F1 Score:\", f1_score(all_labels, all_preds, average='weighted'))          # Use 'weighted' for multiclass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T02:34:58.800627Z","iopub.execute_input":"2024-12-13T02:34:58.800935Z","iopub.status.idle":"2024-12-13T02:34:58.816324Z","shell.execute_reply.started":"2024-12-13T02:34:58.800909Z","shell.execute_reply":"2024-12-13T02:34:58.815503Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8308631211857018\nPrecision: 0.8210572226345487\nRecall: 0.8308631211857018\nF1 Score: 0.8236964904806758\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score\nprint(\"Accuracy:\", balanced_accuracy_score(all_labels, all_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T02:43:07.697385Z","iopub.execute_input":"2024-12-13T02:43:07.697739Z","iopub.status.idle":"2024-12-13T02:43:07.705217Z","shell.execute_reply.started":"2024-12-13T02:43:07.697710Z","shell.execute_reply":"2024-12-13T02:43:07.704366Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7103244937895423\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"torch.save(model.state_dict(), 'effnet_skincancer2_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2024-12-13T02:34:33.498064Z","iopub.execute_input":"2024-12-13T02:34:33.498870Z","iopub.status.idle":"2024-12-13T02:34:33.586102Z","shell.execute_reply.started":"2024-12-13T02:34:33.498832Z","shell.execute_reply":"2024-12-13T02:34:33.585313Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}